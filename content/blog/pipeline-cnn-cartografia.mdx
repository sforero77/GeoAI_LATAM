---
title: "De Cero a Producción: Pipeline Completo de CNN para Cartografía"
excerpt: "Guía práctica sobre todo el flujo de trabajo para entrenar redes convolucionales en tareas cartográficas: desde el etiquetado de imágenes satelitales hasta el despliegue en producción."
date: "2025-11-28"
tags: ["Deep-Learning", "CNN", "PyTorch", "Cartografía", "MLOps"]
author: "GeoAI LATAM"
---

# De Cero a Producción: Pipeline Completo de CNN para Cartografía

Entrenar un modelo de deep learning para cartografía automatizada no es solo escribir código de PyTorch. Es un proceso end-to-end que va desde conseguir datos de calidad hasta monitorear el modelo en producción. En este artículo documentamos todo el pipeline.

## Fase 1: Etiquetado de Datos (El 80% del Trabajo)

### Herramientas Esenciales

**Para imágenes satelitales:**
- **QGIS**: Plugin Semi-Automatic Classification
- **Label Studio**: Interfaz web moderna, ideal para equipos
- **CVAT**: Computer Vision Annotation Tool de Intel
- **Roboflow**: Plataforma all-in-one (gratuita para pequeños proyectos)

### Estrategia de Etiquetado

```python
# Estructura recomendada de dataset
dataset/
├── images/
│   ├── train/
│   ├── val/
│   └── test/
├── masks/
│   ├── train/
│   ├── val/
│   └── test/
└── metadata.json
```

**Tips de etiquetado:**
1. **Consistencia es clave**: Define reglas claras (¿un edificio pequeño es edificio o ruido?)
2. **Calidad > Cantidad**: 100 imágenes bien etiquetadas > 1000 mal etiquetadas
3. **Valida entre etiquetadores**: Inter-annotator agreement > 0.85
4. **Usa proyectos de referencia**: OpenStreetMap, SpaceNet, xBD datasets

## Fase 2: Preparación del Dataset

### Dividir inteligentemente

```python
from sklearn.model_selection import train_test_split
import geopandas as gpd

# No dividir aleatoriamente - separar geográficamente
# para evaluar generalización

def split_spatially(gdf, test_size=0.2):
    """Split dataset por regiones geográficas"""
    regions = gdf.dissolve(by='region')
    train_regions, test_regions = train_test_split(
        regions, test_size=test_size, random_state=42
    )

    train_data = gdf[gdf['region'].isin(train_regions.index)]
    test_data = gdf[gdf['region'].isin(test_regions.index)]

    return train_data, test_data
```

### Data Augmentation Geoespacial

```python
import albumentations as A

transform = A.Compose([
    A.RandomRotate90(p=0.5),
    A.Flip(p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.GaussNoise(p=0.2),

    # Específico para satelital
    A.RandomGamma(p=0.3),  # Variaciones de iluminación
    A.CLAHE(p=0.2),        # Mejora de contraste local
    A.ChannelShuffle(p=0.1),  # Solo si usas RGB
])
```

## Fase 3: Arquitecturas CNN para Cartografía

### U-Net: El Estándar de Oro

```python
import torch
import torch.nn as nn
import segmentation_models_pytorch as smp

# U-Net con encoder pre-entrenado
model = smp.Unet(
    encoder_name="resnet50",        # Backbone
    encoder_weights="imagenet",     # Pre-trained
    in_channels=3,                  # RGB (o más para multiespectral)
    classes=5,                      # Número de clases
)
```

### Otras arquitecturas a considerar

- **DeepLabV3+**: Excelente para fronteras precisas
- **FPN (Feature Pyramid Network)**: Multi-escala
- **MANet**: Attention mechanisms
- **PAN**: Path Aggregation Network

## Fase 4: Entrenamiento y Optimización

### Métricas específicas para segmentación

```python
from torchmetrics import JaccardIndex, F1Score, Precision, Recall

metrics = {
    'iou': JaccardIndex(num_classes=5, task='multiclass'),
    'f1': F1Score(num_classes=5, task='multiclass'),
    'precision': Precision(num_classes=5, task='multiclass'),
    'recall': Recall(num_classes=5, task='multiclass'),
}
```

### Hiperparámetros críticos

| Parámetro | Valor inicial | Notas |
|-----------|---------------|-------|
| Learning Rate | 1e-4 | Usar scheduler (ReduceLROnPlateau) |
| Batch Size | 8-16 | Depende de GPU (imágenes grandes) |
| Optimizer | AdamW | Mejor que Adam para visión |
| Loss Function | DiceLoss + CE | Combo potente para segmentación |
| Epochs | 50-100 | Con early stopping |

### Gestión de experimentos

```python
import wandb

# Integración con Weights & Biases
wandb.init(project="cartografia-cnn")

wandb.config.update({
    "learning_rate": 1e-4,
    "architecture": "U-Net ResNet50",
    "dataset": "edificios-latam-v2",
    "epochs": 100,
})

# Log durante entrenamiento
wandb.log({"train_loss": loss, "val_iou": iou})
```

## Fase 5: Evaluación Rigurosa

### Más allá de métricas numéricas

1. **Inspección visual**: Revisa predicciones manualmente
2. **Error analysis**: ¿Dónde falla? (fronteras, objetos pequeños, sombras)
3. **Generalización geográfica**: Prueba en regiones no vistas
4. **Robustez**: Diferentes estaciones, sensores, resoluciones

## Fase 6: Inferencia en Producción

### Optimización del modelo

```python
# Exportar a ONNX (más rápido, portátil)
import torch.onnx

dummy_input = torch.randn(1, 3, 512, 512)
torch.onnx.export(
    model,
    dummy_input,
    "modelo_cartografia.onnx",
    opset_version=11,
    input_names=['input'],
    output_names=['output']
)
```

### Inferencia batch para grandes áreas

```python
from rasterio.windows import Window
import rasterio

def predict_large_raster(raster_path, model, tile_size=512):
    """Predicción por tiles para no saturar memoria"""
    with rasterio.open(raster_path) as src:
        for ji, window in src.block_windows(1):
            # Leer tile
            tile = src.read(window=window)

            # Predecir
            prediction = model(tile)

            # Escribir resultado
            # ... (código de escritura)
```

## Lecciones Aprendidas

1. **Etiquetado**: Invierte más tiempo aquí, ahorra después
2. **Baseline primero**: Entrena modelo simple antes que arquitecturas complejas
3. **Validación geográfica**: Split aleatorio no es suficiente
4. **Monitoreo continuo**: El modelo degrada con el tiempo (nuevas construcciones, cambios)
5. **Documenta todo**: Decisiones de diseño, experimentos fallidos, hyperparams

## Próximos Pasos

- Self-supervised learning para reducir necesidad de etiquetas
- Foundation models (SAM, Prithvi) + fine-tuning
- Active learning para etiquetar casos difíciles
- Multi-temporal analysis (series de tiempo)

## Recursos

- **Datasets**: SpaceNet, xBD, DOTA, iSAID
- **Código**: [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- **Cursos**: Fast.ai, Coursera Deep Learning Specialization

---

**¿Trabajando en un proyecto de cartografía automatizada?** Comparte tus desafíos en los comentarios. Estamos aquí para aprender juntos.
